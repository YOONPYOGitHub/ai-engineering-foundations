# 1.4 The AI Engineering Stack

> **"AI Engineering은 새로운 레이어를 추가했지만, 기존 엔지니어링 원칙은 여전히 유효하다"**

[← 목차로 돌아가기](./README.md)

---

## 📋 목차

- [개요](#개요)
- [Three Layers of the AI Stack](#three-layers-of-the-ai-stack)
- [AI Engineering Versus ML Engineering](#ai-engineering-versus-ml-engineering)
- [AI Engineering Versus Full-Stack Engineering](#ai-engineering-versus-full-stack-engineering)
- [AI Engineer의 역할](#ai-engineer의-역할)
- [핵심 요약](#핵심-요약)

---

## 개요

### AI Engineering Stack이란?

**정의:**
```
AI 애플리케이션을 만들고 운영하는 데 필요한
모든 기술, 도구, 프로세스의 집합
```

**왜 중요한가?**
- 역할 정의 (누가 무엇을 하는가?)
- 기술 스택 선택 (어떤 도구를 쓰는가?)
- 팀 구성 (어떤 전문성이 필요한가?)
- 커리어 경로 (어떤 스킬을 배워야 하는가?)

### 전통적 ML Stack과의 차이

**Traditional ML (2010s):**
```
문제 정의 → 데이터 수집 → 레이블링 → 
특징 엔지니어링 → 모델 학습 → 평가 → 배포
```

**AI Engineering (2020s):**
```
문제 정의 → 모델 선택 → 프롬프트 엔지니어링 →
컨텍스트 구성 (RAG) → 평가 → 최적화 → 배포
```

**핵심 차이:**
- 모델 개발 → 모델 활용
- 데이터 레이블링 → 프롬프트 작성
- 학습 (Training) → 적응 (Adaptation)

---

## Three Layers of the AI Stack

### 계층 구조

```
┌─────────────────────────────────────┐
│     Application Layer (Layer 3)     │ ← 사용자가 보는 것
│     - UI/UX                          │
│     - 비즈니스 로직                   │
│     - 워크플로우                      │
└─────────────────────────────────────┘
              ↓ ↑
┌─────────────────────────────────────┐
│      AI/ML Layer (Layer 2)          │ ← AI Engineer의 영역
│      - Foundation Models             │
│      - Prompt Engineering            │
│      - RAG, Agents, Finetuning       │
│      - Evaluation                    │
└─────────────────────────────────────┘
              ↓ ↑
┌─────────────────────────────────────┐
│   Infrastructure Layer (Layer 1)    │ ← ML Engineer/MLOps
│   - Model Serving                    │
│   - Vector Databases                 │
│   - GPU/Cloud                        │
│   - Monitoring                       │
└─────────────────────────────────────┘
```

### Layer 1: Infrastructure Layer

**목적:**
- AI 워크로드 실행
- 데이터 저장 및 검색
- 성능 모니터링

**주요 컴포넌트:**

**1. Compute (연산)**
```
GPU:
- NVIDIA A100, H100
- 학습 및 추론
- 비용: $1-4/시간

CPU:
- 간단한 추론
- 전처리
- 저렴

TPU (Google):
- TensorFlow 최적화
- Google Cloud 전용
```

**2. Model Serving**
```
목적: 모델을 API로 노출

자체 호스팅:
- vLLM, TGI (Text Generation Inference)
- TensorRT, ONNX Runtime
- 장점: 완전한 통제
- 단점: 운영 부담

Model-as-a-Service:
- OpenAI API, Anthropic
- Hugging Face Inference API
- 장점: 쉬움, 빠름
- 단점: 비용, 종속성
```

**3. Vector Databases**
```
목적: Embedding 저장 및 검색 (RAG용)

Pinecone:
- Managed service
- 쉬운 시작
- 비용 예측 가능

Weaviate:
- 오픈소스 + Enterprise
- 멀티모달 지원
- Self-hosted 가능

Qdrant:
- 오픈소스
- Rust (빠름)
- 필터링 강력

Chroma:
- 오픈소스
- Python 친화적
- 로컬 개발 용이

Milvus:
- 오픈소스
- 확장성 우수
- 복잡한 설정
```

**4. Cloud Platforms**
```
AWS:
- SageMaker (ML 플랫폼)
- Bedrock (FM API)
- EC2 + GPU

Google Cloud:
- Vertex AI
- TPU 접근
- Gemini API

Azure:
- Azure OpenAI Service
- Azure ML
- Enterprise 친화적

전용 AI Cloud:
- Lambda Labs (저렴한 GPU)
- RunPod
- Vast.ai
```

**5. Orchestration**
```
Kubernetes:
- 컨테이너 오케스트레이션
- 스케일링
- 복잡함

Ray:
- 분산 연산
- 하이퍼파라미터 튜닝
- Python 네이티브

Airflow:
- 데이터 파이프라인
- 스케줄링
- 모니터링
```

**6. Monitoring & Observability**
```
시스템 메트릭:
- Prometheus, Grafana
- CPU, GPU, 메모리
- Latency, Throughput

AI 메트릭:
- LangSmith, Arize
- 프롬프트 추적
- 출력 품질
- Hallucination 검출

로깅:
- ELK Stack
- Datadog
- CloudWatch
```

### Layer 2: AI/ML Layer

**목적:**
- Foundation Models 활용
- AI 기능 구현
- 모델 성능 최적화

**주요 컴포넌트:**

**1. Foundation Models**
```
Commercial:
- GPT-4, GPT-4-turbo (OpenAI)
- Claude 3 (Anthropic)
- Gemini (Google)
- 장점: 최고 성능
- 단점: 비용, API 종속

Open Source:
- Llama 3 (Meta)
- Mistral
- Qwen
- 장점: 통제, 프라이버시
- 단점: 호스팅 필요

Specialized:
- Code: CodeLlama, StarCoder
- Vision: CLIP, LLaVA
- Embedding: Sentence-BERT
```

**2. Model Adaptation Techniques**
```
Prompt Engineering:
- Zero-shot, Few-shot
- Chain-of-Thought
- 빠름, 저렴
- 유연성 제한적

RAG (Retrieval-Augmented Generation):
- 외부 지식 통합
- 최신 정보
- Hallucination 감소
- 검색 품질 중요

Finetuning:
- 특정 태스크/도메인 최적화
- 더 나은 성능
- 시간, 데이터 필요
- PEFT (LoRA, QLoRA)

Agents:
- 도구 사용
- 다단계 추론
- 복잡한 태스크
- 신뢰성 도전
```

**3. Evaluation**
```
자동 평가:
- Exact match
- Similarity (BLEU, ROUGE)
- AI-as-a-judge

사람 평가:
- 품질 확인
- Edge case
- 사용자 피드백

벤치마크:
- MMLU (지식)
- HumanEval (코딩)
- MT-Bench (대화)
```

**4. Data Pipeline**
```
Data Collection:
- 웹 스크래핑
- API 통합
- 사용자 생성 콘텐츠

Data Processing:
- 청킹 (RAG용)
- Embedding 생성
- 필터링, 정제

Data Synthesis:
- AI 생성 데이터
- Data Augmentation
- 레이블 생성
```

**5. Frameworks & Tools**
```
LLM Frameworks:
- LangChain (Python/JS)
- LlamaIndex
- Haystack
- 장점: 빠른 프로토타이핑
- 단점: 추상화 오버헤드

Prompt Management:
- Langfuse
- PromptLayer
- 버전 관리
- A/B 테스트

Evaluation:
- RAGAS (RAG 평가)
- TruLens
- Phoenix (Arize)
```

### Layer 3: Application Layer

**목적:**
- 사용자 인터페이스
- 비즈니스 로직
- 워크플로우 통합

**주요 컴포넌트:**

**1. User Interface**
```
Web:
- React, Vue, Svelte
- Gradio (빠른 프로토타입)
- Streamlit (데이터 앱)

Mobile:
- React Native
- Flutter
- Native (iOS/Android)

Chat:
- Slack, Discord 봇
- WhatsApp
- 커스텀 챗봇 UI
```

**2. Application Logic**
```
API Layer:
- FastAPI, Flask (Python)
- Express (Node.js)
- REST, GraphQL

State Management:
- 대화 히스토리
- 사용자 세션
- 컨텍스트 유지

Authentication:
- OAuth
- API keys
- RBAC (역할 기반 접근)
```

**3. Integrations**
```
Third-party APIs:
- CRM (Salesforce, HubSpot)
- Productivity (Notion, Slack)
- Databases (SQL, NoSQL)

Webhooks:
- 실시간 업데이트
- 이벤트 기반 트리거

Plugins:
- Browser extensions
- IDE plugins (VS Code)
- Desktop apps
```

**4. Workflow Automation**
```
Zapier, Make:
- No-code 통합
- 워크플로우 자동화

n8n:
- 오픈소스
- Self-hosted

Custom:
- 복잡한 로직
- 완전한 통제
```

---

## AI Engineering Versus ML Engineering

### 핵심 차이점

**철학:**
```
ML Engineering:
"어떻게 모델을 만들 것인가?"
→ Model Development

AI Engineering:
"어떻게 모델을 활용할 것인가?"
→ Model Utilization
```

### 상세 비교

**1. 워크플로우**

**ML Engineering:**
```
1. 문제 정의
   - 비즈니스 문제 → ML 문제
   - 메트릭 정의

2. 데이터 수집
   - 데이터 소스 파악
   - 수천~수백만 샘플

3. 데이터 레이블링
   - 사람이 레이블
   - 비용: $수만~$수백만
   - 시간: 수주~수개월

4. 특징 엔지니어링
   - 어떤 특징이 중요?
   - 도메인 지식
   - 실험

5. 모델 선택 & 학습
   - 알고리즘 선택
   - 하이퍼파라미터 튜닝
   - 학습 시간: 시간~수일

6. 평가 & 반복
   - 성능 측정
   - 개선
   - 재학습

7. 배포
   - 인프라 설정
   - 서빙
   - 모니터링

시간: 3-6개월 (최소)
```

**AI Engineering:**
```
1. 문제 정의
   - 비즈니스 문제
   - 성공 지표

2. 모델 선택
   - GPT-4? Claude? Llama?
   - API vs Self-hosted
   - 시간: 수시간~수일

3. 프롬프트 엔지니어링
   - 지시사항 작성
   - Few-shot 예시
   - 반복 개선
   - 시간: 수시간~수일

4. 컨텍스트 구성
   - RAG 설정
   - 데이터베이스 연결
   - 도구/API 통합
   - 시간: 수일~수주

5. 평가
   - 테스트 세트
   - 자동/사람 평가
   - 반복

6. 최적화
   - Caching
   - Batching
   - 모델 교체

7. 배포
   - API 통합
   - 모니터링
   - 사용자 피드백

시간: 수일~수주 (프로토타입)
```

**2. 데이터**

| 측면 | ML Engineering | AI Engineering |
|------|---------------|---------------|
| **수집** | 수천~수백만 샘플 | 수십~수백 샘플 (few-shot) |
| **레이블링** | 사람이 레이블 (비용 높음) | 프롬프트로 제시 (거의 무료) |
| **품질** | 매우 중요 (모델 학습) | 중요 (예시, RAG) |
| **양** | 많을수록 좋음 | 품질 > 양 |
| **업데이트** | 재학습 필요 | 프롬프트/RAG 업데이트 |

**예시:**

ML Engineering (감성 분석):
```
1. 10,000개 리뷰 수집
2. 각 리뷰에 긍정/부정 레이블
   - 비용: $0.05 × 10,000 = $500
   - 시간: 2주
3. 모델 학습 (BERT finetuning)
   - 시간: 수시간
4. 정확도: 92%
```

AI Engineering (감성 분석):
```
1. 10개 예시 준비 (few-shot)
2. 프롬프트 작성:
   "다음 리뷰의 감성을 분류하세요.
    긍정/부정으로만 답하세요.
    
    예시:
    리뷰: '제품이 훌륭해요!' → 긍정
    리뷰: '최악입니다.' → 부정
    ...
    
    리뷰: {user_input} → "
    
3. 테스트 및 반복
   - 시간: 수시간
4. 정확도: 85-90%
```

**3. 모델**

| 측면 | ML Engineering | AI Engineering |
|------|---------------|---------------|
| **개발** | 직접 학습 | 기존 모델 사용 |
| **아키텍처** | 선택/설계 | 제공됨 |
| **크기** | 적절한 크기 선택 | 대부분 매우 큼 |
| **도메인** | Task-specific | General-purpose |
| **통제** | 완전한 통제 | 제한적 (API) |
| **비용** | 학습 비용 (upfront) | 추론 비용 (ongoing) |

**4. 평가**

**ML Engineering:**
```
명확한 메트릭:
- Accuracy, F1, AUC-ROC
- 객관적 측정
- 자동 평가

테스트 세트:
- 고정됨
- 재현 가능
- 통계적 유의성
```

**AI Engineering:**
```
주관적 요소:
- "좋은 답변"의 정의?
- 창의성, 톤, 스타일
- 사람 판단 필요

다양한 방법:
- Exact match (제한적)
- AI-as-a-judge
- 사용자 피드백
- A/B 테스트

도전 과제:
- Hallucination
- 일관성
- 비용 (평가 자체가 비쌈)
```

**5. 스킬셋**

**ML Engineering:**
```
수학/통계:
- 선형대수
- 확률/통계
- 최적화

알고리즘:
- 다양한 ML 알고리즘
- 각 알고리즘의 장단점
- 언제 무엇을 쓸지

구현:
- TensorFlow, PyTorch
- Model architecture
- Training loops

데이터:
- Feature engineering
- Data augmentation
- 데이터 품질 관리

시스템:
- 분산 학습
- GPU 프로그래밍
- 메모리 최적화
```

**AI Engineering:**
```
프롬프트 엔지니어링:
- 명확한 지시사항
- Few-shot learning
- Chain-of-Thought

시스템 설계:
- RAG 아키텍처
- Agent 설계
- 워크플로우 구성

평가:
- 테스트 디자인
- 메트릭 정의
- 품질 보증

최적화:
- Latency 개선
- 비용 절감
- Caching 전략

통합:
- API 사용
- 데이터베이스 연결
- 써드파티 서비스

제품 감각:
- 사용자 경험
- Edge case 처리
- 신뢰 구축
```

**6. 관심사 & 도전 과제**

**ML Engineering:**
```
주요 도전:
- Overfitting / Underfitting
- 데이터 부족
- 클래스 불균형
- Feature selection
- 모델 복잡도 vs 성능

최적화:
- 하이퍼파라미터 튜닝
- 학습 속도
- 메모리 사용
- 모델 압축
```

**AI Engineering:**
```
주요 도전:
- Hallucination
- Prompt injection
- 일관성 부족
- Context length limit
- 비용

최적화:
- 프롬프트 효율성
- API 호출 최소화
- Caching
- 모델 선택 (크기 vs 성능)
```

### 언제 각 접근을 쓰는가?

**ML Engineering이 더 나은 경우:**
```
✅ 특정 도메인 (의료, 금융)
✅ 고성능 필수 (레이턴시 < 10ms)
✅ 레이블된 데이터 풍부
✅ 명확한 task 정의
✅ 프라이버시 중요 (모든 것 in-house)
✅ 장기적 투자 가능
✅ 전문 팀 있음

예:
- 신용카드 사기 탐지
- 의료 이미지 진단
- 추천 시스템 (Netflix, YouTube)
- 음성 인식 (Siri, Alexa)
```

**AI Engineering이 더 나은 경우:**
```
✅ 빠른 프로토타입 필요
✅ 범용 태스크 (요약, 분류, Q&A)
✅ 데이터 부족
✅ 리소스 제한적
✅ 요구사항 변화 많음
✅ 창의성/생성 필요
✅ 빠른 시장 진입

예:
- 고객 지원 챗봇
- 콘텐츠 생성 (마케팅, 코딩)
- 문서 요약/분석
- 이메일 초안 작성
```

**둘 다 필요한 경우:**
```
복잡한 시스템:
- Foundation Model (범용) + Custom Model (전문)
- 예: Copilot = GPT (생성) + Specialized model (코드 이해)

하이브리드 접근:
- AI Engineering으로 빠르게 시작
- 성공 확인 후 ML Engineering으로 최적화
```

### 커리어 전환

**ML Engineer → AI Engineer:**
```
기존 강점:
✓ ML 개념 이해
✓ 평가 방법론
✓ 시스템 사고

새로 배울 것:
□ Prompt engineering
□ Foundation models (특성, 한계)
□ RAG 아키텍처
□ LLM frameworks (LangChain 등)
□ 제품 감각

시간: 1-3개월
```

**Software Engineer → AI Engineer:**
```
기존 강점:
✓ API 통합
✓ 시스템 설계
✓ 제품 개발

새로 배울 것:
□ ML 기초 (확률, 통계)
□ Foundation models
□ Prompt engineering
□ Evaluation 방법론
□ AI 특유의 도전 (hallucination 등)

시간: 2-4개월
```

---

## AI Engineering Versus Full-Stack Engineering

### 유사점

**1. 제품 중심**
```
둘 다:
- 사용자 문제 해결
- End-to-end 책임
- UX 중요
- 빠른 반복
```

**2. 넓은 기술 스택**
```
Frontend:
- UI/UX
- JavaScript/TypeScript
- React, Vue, Svelte

Backend:
- API 설계
- 데이터베이스
- 인증/인가

DevOps:
- 배포
- CI/CD
- 모니터링
```

**3. 통합 능력**
```
- 다양한 서비스 연결
- API 사용
- 써드파티 통합
- 문제 해결
```

### 차이점

**1. 핵심 추가 요소**

**AI Engineer = Full-Stack Engineer + AI:**
```
추가 레이어:
+ Foundation Models
+ Prompt Engineering
+ RAG / Agents / Finetuning
+ AI 평가
+ 확률적 시스템 다루기
```

**2. 시스템의 본질**

**Full-Stack:**
```
결정론적 (Deterministic):
- 입력 A → 항상 출력 B
- 예측 가능
- 디버깅 명확
- 테스트 용이

예:
input: "user123"
→ 항상 같은 사용자 정보 반환
```

**AI Engineering:**
```
확률적 (Probabilistic):
- 입력 A → 다양한 출력 (B, C, D...)
- 예측 불가능
- 디버깅 어려움
- 테스트 복잡

예:
input: "재미있는 이야기 써줘"
→ 매번 다른 이야기

temperature=0으로 해도 완벽히 같지 않을 수 있음
```

**3. 도전 과제**

**Full-Stack:**
```
- 버그 (고칠 수 있음)
- 성능 (최적화 가능)
- 확장성 (아키텍처)
- 보안 (명확한 베스트 프랙티스)
```

**AI Engineering:**
```
+ Hallucination (완전히 제거 불가)
+ Prompt injection (새로운 위협)
+ 일관성 (어려움)
+ 비용 (예측 어려움)
+ 윤리/편향 (복잡함)
+ "올바른 답"의 정의 (주관적)
```

**4. 테스트 & 품질 보증**

**Full-Stack:**
```
Unit tests:
assert add(2, 3) == 5

Integration tests:
API 호출 → 예상 응답

E2E tests:
사용자 플로우 시뮬레이션

→ 통과/실패 명확
```

**AI Engineering:**
```
Quality checks:
- 이 요약이 "좋은가"?
- 톤이 적절한가?
- Hallucination 있나?
- 사용자가 만족할까?

→ 명확하지 않음
→ 샘플링 필요
→ 사람 평가 필요
→ 지속적 모니터링
```

**5. 비용 모델**

**Full-Stack:**
```
고정 비용 주도:
- 서버 대수
- 데이터베이스
- CDN

예측 가능:
- 사용자 1000명 → $X/월
- 확장 시 선형적 증가
```

**AI Engineering:**
```
변동 비용 주도:
- API 호출 당 비용
- 토큰 수
- 모델 크기

예측 어려움:
- 사용자 행동에 따라 변동
- 긴 대화 = 높은 비용
- 최적화 지속 필요

예:
기능 추가 → 프롬프트 길어짐 → 비용 2배 증가
```

### 실제 예시

**Full-Stack 앱 (TODO 리스트):**
```python
# Backend
@app.post("/todos")
def create_todo(title: str, user_id: int):
    todo = Todo(title=title, user_id=user_id)
    db.add(todo)
    return {"id": todo.id, "title": title}

# 예측 가능:
# - 항상 같은 동작
# - 명확한 에러 처리
# - 테스트 간단
```

**AI-Powered 앱 (스마트 TODO):**
```python
# Backend
@app.post("/todos/smart")
async def create_smart_todo(description: str, user_id: int):
    # AI가 task 분해
    prompt = f"""
    사용자 설명: {description}
    이를 실행 가능한 subtask로 나누세요.
    """
    
    subtasks = await llm.complete(prompt)  # 🎲 확률적
    
    # 문제들:
    # - subtasks 품질? (평가 필요)
    # - 비용? (토큰 수에 따라)
    # - Latency? (LLM 응답 시간)
    # - Hallucination? (이상한 task)
    
    return {"subtasks": subtasks}
```

---

## AI Engineer의 역할

### 핵심 활동

**1. Model Selection (모델 선택)**
```
질문:
- 어떤 모델? GPT-4, Claude, Llama?
- API vs Self-hosted?
- 크기 vs 성능 trade-off?

고려사항:
- 성능 (벤치마크)
- 비용 ($/1M tokens)
- Latency (응답 시간)
- 기능 (vision, function calling?)
- 프라이버시 (데이터 보관?)
```

**2. Prompt Engineering (프롬프트 엔지니어링)**
```
활동:
- 명확한 지시사항 작성
- Few-shot 예시 제공
- Output format 지정
- 반복 개선

예:
V1: "이메일 분류해"
V2: "이메일을 긴급/일반/스팸으로 분류. 한 단어로만."
V3: + 예시 3개
V4: + "확실하지 않으면 '불분명' 출력"
```

**3. Context Construction (컨텍스트 구성)**
```
RAG:
- 어떤 데이터?
- 어떻게 검색?
- 몇 개 결과?
- 어떻게 통합?

Tools/APIs:
- 어떤 도구?
- 언제 호출?
- 에러 처리?

Memory:
- 대화 히스토리
- 사용자 프로파일
- 세션 관리
```

**4. Evaluation (평가)**
```
메트릭 정의:
- 무엇이 "좋은" 출력?
- 어떻게 측정?

테스트 세트:
- 대표적 예시
- Edge cases
- 실패 시나리오

반복:
- 실패 분석
- 프롬프트 개선
- 모델 교체?
```

**5. Optimization (최적화)**
```
Latency:
- Caching (자주 묻는 질문)
- Streaming (답변을 점진적으로)
- Smaller models (가능한 경우)
- Parallel calls

비용:
- Prompt compression
- 더 저렴한 모델 (간단한 태스크)
- Batching
- Caching

품질:
- Few-shot → Finetuning
- RAG 개선
- Ensemble (여러 모델)
```

**6. Safety & Guardrails (안전장치)**
```
Input validation:
- Prompt injection 방어
- 유해 콘텐츠 필터

Output filtering:
- 민감 정보 마스킹
- 품질 체크
- Fallback (AI 실패 시)

Monitoring:
- 이상 탐지
- 사용자 신고
- 자동 알림
```

### 하루의 일과

**예시: AI Engineer at SaaS Company**

```
09:00 - 10:00 | 팀 Standup & Planning
- 어제 진행 상황
- 오늘 목표
- 블로커 논의

10:00 - 12:00 | 개발
- 새 기능: 문서 요약
- RAG 파이프라인 구축
- 청킹 전략 실험
  → 500 tokens vs 1000 tokens?
- Prompt 작성 및 테스트

12:00 - 13:00 | 점심

13:00 - 14:00 | 평가 회의
- 지난 주 배포한 기능 리뷰
- 메트릭 체크:
  → Accuracy: 85% (목표: 90%)
  → User feedback: 👍 80%
  → Cost: $50/day (예산 내)
- 개선 방향 논의

14:00 - 16:00 | 디버깅 & 최적화
- 사용자 리포트: 이상한 답변
- 재현 시도
- Prompt 개선
  → "X를 하지 마세요" 추가
- 테스트 세트로 검증
- 배포 (Canary 10%)

16:00 - 17:00 | 학습 & 실험
- 새 논문 읽기: "Better RAG with..."
- 작은 실험: HyDE 시도
- 결과 기록

17:00 - 18:00 | 문서화 & 회의
- ADR 작성 (왜 이 접근?)
- Product와 다음 분기 계획
- 새 use case 논의
```

### 필요한 T-Shaped 스킬

**깊이 (Depth) - 전문성:**
```
AI/ML:
- Foundation models (작동 방식)
- Prompt engineering
- RAG, Agents, Finetuning
- Evaluation 방법론
```

**넓이 (Breadth) - 폭넓은 지식:**
```
Software Engineering:
- API 설계
- 데이터베이스
- 시스템 설계

Data:
- 데이터 처리
- ETL
- SQL

Product:
- 사용자 경험
- 요구사항 이해
- 우선순위

Communication:
- 기술/비기술 팀과 협업
- 문서화
- 프레젠테이션
```

---

## 핵심 요약

### The AI Engineering Stack

**Three Layers:**
```
Application Layer:
→ UI/UX, 비즈니스 로직

AI/ML Layer:
→ Foundation Models, Prompt, RAG

Infrastructure Layer:
→ GPU, Serving, Monitoring
```

### AI Engineering vs ML Engineering

**핵심 차이:**
```
┌───────────────┬─────────────────┬─────────────────┐
│               │ ML Engineering   │ AI Engineering   │
├───────────────┼─────────────────┼─────────────────┤
│ 철학           │ Model Dev        │ Model Use        │
│ 시간           │ 3-6개월          │ 수일-수주        │
│ 데이터         │ 수천-수백만      │ 수십-수백        │
│ 비용           │ 학습 (upfront)   │ 추론 (ongoing)   │
│ 스킬           │ 수학, 알고리즘   │ Prompt, 통합     │
└───────────────┴─────────────────┴─────────────────┘
```

**언제 무엇을?**
- ML Eng: 전문 도메인, 고성능, 장기 투자
- AI Eng: 빠른 프로토타입, 범용, 빠른 시장 진입

### AI Engineering vs Full-Stack

**유사점:**
- 제품 중심, 넓은 스택, 통합 능력

**차이점:**
- AI Eng = Full-Stack + AI Layer
- 확률적 vs 결정론적
- 새로운 도전 (hallucination, prompt injection)

### AI Engineer의 핵심 활동

```
1. Model Selection (어떤 모델?)
2. Prompt Engineering (어떻게 지시?)
3. Context Construction (무엇을 제공?)
4. Evaluation (얼마나 좋은가?)
5. Optimization (더 빠르게, 저렴하게)
6. Safety (안전한가?)
```

### 성공하는 AI Engineer

**Technical:**
- Foundation Models 이해
- Prompt engineering 마스터
- Evaluation 체계 구축
- 지속적 최적화

**Non-Technical:**
- 제품 감각
- 사용자 공감
- 빠른 반복
- 커뮤니케이션

---

**다음**: [Chapter 2: Understanding Foundation Models →](../chapter2/README.md)

[← 목차로 돌아가기](./README.md)
