# 2.1 Training Data (훈련 데이터)

> "AI 모델은 학습한 데이터만큼만 좋다"

[← 목차로 돌아가기](./README.md)

---

## 📋 목차
- [핵심 개념](#핵심-개념)
- [2.1.1 데이터 소스의 현실](#211-데이터-소스의-현실)
- [2.1.2 Multilingual Models](#212-multilingual-models-다국어-모델)
- [2.1.3 Domain-Specific Models](#213-domain-specific-models-도메인-특화-모델)
- [핵심 요약](#핵심-요약)
- [토론 질문](#토론-질문)

---

## 핵심 개념

모델의 성능은 훈련 데이터에 크게 의존합니다. **데이터에 없는 내용은 모델이 학습할 수 없습니다.**

예시:
- 훈련 데이터에 베트남어가 없으면 → 영어-베트남어 번역 불가
- 동물 사진만 학습했으면 → 식물 분류 불가

---

## 2.1.1 데이터 소스의 현실

### Common Crawl: 가장 흔한 데이터 소스

**기본 정보**
- 비영리 단체가 운영하는 웹 크롤링 데이터셋
- 매월 20-30억 개의 웹페이지 크롤링
- GPT-3, Gemini 등 대부분의 주요 모델에 사용됨

**Google의 C4 (Colossal Clean Crawled Corpus)**
- Common Crawl의 정제된 버전
- 하지만 여전히 품질 문제 존재

### 데이터 품질 문제

**Common Crawl에 포함된 문제적 콘텐츠**
- ❌ 클릭베이트
- ❌ 가짜 뉴스와 잘못된 정보
- ❌ 선전 및 음모론
- ❌ 인종차별, 성차별적 콘텐츠
- ❌ 신뢰할 수 없는 웹사이트

**Washington Post 연구 결과**
- 상위 1,000개 웹사이트 중 다수가 NewsGuard 신뢰도 척도에서 낮은 점수
- "인터넷에서 본 가장 의심스러운 모든 웹사이트" 포함

### 필터링 시도

**OpenAI의 GPT-2 접근법**
- Reddit에서 최소 3개 이상의 upvote를 받은 링크만 사용
- 한계: Reddit도 완벽한 품질 기준은 아님

**근본적 문제**
> "우리가 원하는 데이터가 아니라 우리가 가진 데이터를 사용"

### 데이터 품질 vs 데이터 양

**중요한 발견**
- 7B 토큰의 **고품질** 코딩 데이터로 학습한 1.3B 파라미터 모델
- → 훨씬 큰 모델을 능가 (여러 코딩 벤치마크에서)
- 출처: Gunasekar et al. (2023)

**세 가지 황금 목표**
1. **Quantity** (양): 충분한 데이터
2. **Quality** (품질): 정확하고 신뢰할 수 있는 데이터
3. **Diversity** (다양성): 다양한 주제와 스타일

---

## 2.1.2 Multilingual Models (다국어 모델)

### 언어별 데이터 불균형

**Common Crawl의 언어 분포**

#### 상위 언어들 (1% 이상)

| 언어 | 코드 | 사용 인구(백만) | CC 비율 |
|------|------|----------------|---------|
| 영어 | en | 1,452 | 45.88% |
| 러시아어 | ru | 258 | 5.97% |
| 독일어 | de | 134 | 5.88% |
| 중국어 | zh | 1,118 | 4.87% |
| 일본어 | jp | 125 | 4.79% |
| 프랑스어 | fr | 274 | 4.73% |
| 스페인어 | es | 548 | 4.47% |
| 이탈리아어 | it | 68 | 2.57% |
| 네덜란드어 | nl | 30 | 2.06% |
| 폴란드어 | pl | 45 | 1.66% |
| 포르투갈어 | pt | 257 | 1.15% |
| 베트남어 | vi | 85 | 1.03% |

#### 심각하게 과소 대표되는 언어들

| 언어 | 사용자(백만) | 세계 인구 % | CC % | 불균형 비율 |
|------|------------|------------|------|-----------|
| 펀자브어 | 113 | 1.41% | 0.0061% | **231.56** |
| 스와힐리어 | 71 | 0.89% | 0.0077% | 115.26 |
| 우르두어 | 231 | 2.89% | 0.0274% | 105.38 |
| 칸나다어 | 64 | 0.80% | 0.0122% | 65.57 |
| 텔루구어 | 95 | 1.19% | 0.0183% | 64.89 |
| 구자라트어 | 62 | 0.78% | 0.0126% | 61.51 |
| 마라티어 | 99 | 1.24% | 0.0213% | 58.10 |
| 벵골어 | 272 | 3.40% | 0.0930% | 36.56 |
| **영어 (비교)** | 1,452 | 18.15% | 45.88% | **0.40** |

> 💡 **불균형 비율**이 높을수록 해당 언어가 더 과소 대표됨

### 성능에 미치는 영향

#### 1. MMLU 벤치마크 성능 (GPT-4)

**MMLU**: 57개 주제에 걸친 14,000개의 객관식 문제

- 영어에서 최고 성능
- 과소 대표 언어(텔루구어, 마라티어, 펀자브어)에서 현저히 낮은 성능

![성능 차이 예시]
```
영어:     ████████████████████ 86%
중국어:   ████████████████     75%
텔루구어: ██████               30%
```

#### 2. 수학 문제 해결 (Project Euler)

**GPT-4의 6개 수학 문제 성공률**

| 언어 | 성공한 문제 수 | 성공률 |
|------|---------------|--------|
| 영어 | 6 | 100% |
| 아르메니아어 | 2 | 33% |
| 페르시아어 | 2 | 33% |
| 버마어 | 0 | 0% |
| 암하라어 | 0 | 0% |

출처: Yennie Jun, "GPT-4 Can Solve Math Problems—but Not in All Languages"

#### 3. 잘못된 정보 생성 (NewsGuard 연구)

**ChatGPT-3.5에게 중국 관련 허위 정보 작성 요청 (2023년 4월)**

| 언어 | 거부한 경우 | 허위 정보 생성 |
|------|-----------|---------------|
| 영어 | 6/7 (86%) | 1/7 (14%) |
| 간체 중국어 | 0/7 (0%) | 7/7 (100%) |
| 번체 중국어 | 0/7 (0%) | 7/7 (100%) |

> ⚠️ 중국어로 요청하면 모든 경우에 허위 정보를 생성했지만, 영어로는 대부분 거부했습니다.

**왜 이런 차이가 발생할까?**
- Pre-training 데이터의 편향?
- Alignment 데이터의 언어별 차이?
- 중국어 또는 중국 중심 서사의 데이터 부족?

### 토큰화 비효율성

#### 언어별 토큰 길이 차이

**MASSIVE 데이터셋 분석** (100만 개의 짧은 텍스트, 52개 언어)

같은 의미를 표현하는데 필요한 토큰 수:

| 언어 | 중간값 토큰 수 | 영어 대비 비율 |
|------|---------------|---------------|
| 영어 | 7 | 1.0x |
| 스페인어 | ~9 | 1.3x |
| 힌디어 | 32 | 4.6x |
| 버마어 | 72 | **10.3x** |

출처: Yennie Jun

#### 실질적 영향

**버마어로 GPT-4 사용 시:**
```
같은 내용 전달:
- 영어: 7 토큰 생성
- 버마어: 72 토큰 생성

결과:
→ 생성 시간 10배 증가
→ API 비용 10배 증가
```

**왜 이런 차이가 발생하는가?**
- 토크나이저가 주로 영어 데이터로 최적화됨
- 다른 언어의 문자는 더 많은 토큰으로 분할됨
- 예: 한 한글 음절 → 여러 토큰

### 번역 우회 방법의 한계

**아이디어**: 다른 언어 → 영어 번역 → 처리 → 다시 번역

**문제점**:

1. **번역 모델 필요**
   - 과소 대표 언어를 충분히 이해하는 번역 모델 필요
   - 그런 모델이 없다면 번역도 불가능

2. **정보 손실**
   - 일부 언어는 영어에 없는 정보를 인코딩
   - 예: 베트남어의 관계 대명사
     ```
     베트남어: anh, chị, em, cô, bác... (화자 간 관계 표현)
     영어 번역: I, you (관계 정보 손실)
     ```

### 해결책: 언어별 특화 모델

**중국어 모델들**
- ChatGLM
- YAYI
- Llama-Chinese

**기타 언어 모델들**
- **CroissantLLM**: 프랑스어
- **PhoGPT**: 베트남어
- **Jais**: 아랍어
- 그 외 다수...

**장점**:
- 해당 언어에 최적화된 토크나이저
- 언어 특화 데이터로 학습
- 더 나은 성능과 효율성

**단점**:
- 각 언어마다 별도 모델 필요
- 유지보수 비용 증가
- 다국어 태스크에는 적합하지 않음

---

## 2.1.3 Domain-Specific Models (도메인 특화 모델)

### 범용 모델의 한계

**범용 모델이 잘하는 것**
- 코딩
- 법률
- 과학
- 비즈니스
- 스포츠
- 환경 과학
- 일상적인 주제들

**왜?** → Common Crawl에 이런 도메인이 포함되어 있기 때문

### C4 데이터셋의 도메인 분포

**Washington Post (2023) 분석 결과**

주요 카테고리:
- 패턴 및 디자인
- 링크 모음
- 온라인 쇼핑
- 인문학
- 비즈니스 및 산업
- 컴퓨터 및 인터넷
- 사회
- 미디어
- 여가 및 레크리에이션

**한계**: 
- 텍스트 데이터에 대한 분석
- 이미지/비디오는 카테고리화가 어려움

### 벤치마크를 통한 도메인 추론

**CLIP vs Open CLIP 성능 비교**

| 데이터셋 | CLIP (%) | Open CLIP (%) |
|---------|----------|---------------|
| ImageNet | 63.2 | 62.9 |
| ImageNet v2 | - | 62.6 |
| Birdsnap (새) | 37.8 | 46.0 |
| Country211 (국가) | 17.8 | 14.8 |
| Oxford 102 Flowers | 66.7 | 66.0 |
| German Traffic Signs | 32.2 | 42.0 |
| Stanford Cars | 59.4 | 79.3 |
| UCF101 (동작) | 64.5 | 63.1 |

**시사점**:
- 새, 꽃, 자동차, 교통 표지 등 제한된 카테고리
- 세상은 이보다 훨씬 복잡하고 다양함

### 전문 도메인의 도전과제

**범용 모델로 부족한 영역**

#### 1. 신약 개발
**필요 데이터**:
- 단백질 서열
- DNA, RNA 데이터
- 분자 구조
- 임상 시험 결과

**문제**:
- 특수한 형식
- 획득 비용이 매우 높음
- 공개 인터넷에 거의 없음

#### 2. 의료 진단
**필요 데이터**:
- X-ray 이미지
- fMRI 스캔
- CT/MRI 이미지
- 병리 슬라이드

**문제**:
- 개인정보 보호 (HIPAA, GDPR)
- 전문가 라벨링 필요
- 대량 수집 어려움

### 성공적인 도메인 특화 모델들

#### AlphaFold (DeepMind)

**목표**: 단백질 구조 예측

**데이터**:
- 약 100,000개의 알려진 단백질
- 서열 및 3D 구조

**성과**:
- 단백질 구조 예측 혁명
- 신약 개발 가속화
- 2024년 노벨 화학상 수상

#### BioNeMo (NVIDIA)

**목표**: 생체 분자 데이터 처리

**특징**:
- 단백질, DNA, RNA에 특화
- 신약 발견 파이프라인
- 분자 생성 및 최적화

#### Med-PaLM2 (Google)

**목표**: 의료 질문 답변

**접근법**:
- LLM + 의료 데이터
- 의료 벤치마크에서 높은 정확도
- 의사 수준의 답변

**성과**:
- 의료 면허 시험 수준 질문 해결
- 환자 질문에 정확한 답변

### 다른 분야의 가능성

**건축**
- 건축 스케치로 학습한 모델
- Stable Diffusion보다 건축에 특화
- 도면 생성, 디자인 제안

**제조업**
- 공장 도면으로 학습
- ChatGPT보다 제조 프로세스 최적화에 강함
- 생산 계획, 품질 관리

**법률**
- 판례, 법률 문서로 학습
- 계약서 검토, 법률 조언
- 판례 검색 및 분석

**금융**
- 금융 보고서, 시장 데이터
- 리스크 분석, 투자 조언
- 사기 탐지

### 범용 vs 특화 모델 선택

**범용 모델을 사용해야 할 때**:
- ✅ 일반적인 주제
- ✅ 빠른 프로토타이핑
- ✅ 다양한 태스크
- ✅ 데이터 수집이 어려움

**특화 모델을 고려해야 할 때**:
- ✅ 높은 정확도 필요
- ✅ 전문 용어 많음
- ✅ 도메인 특화 데이터 확보 가능
- ✅ 특정 분야에서만 사용

---

## 핵심 요약

### 데이터 품질의 중요성
1. **Common Crawl은 편리하지만 완벽하지 않음**
   - 가짜 뉴스, 편향된 콘텐츠 포함
   - 대부분의 주요 모델이 사용

2. **품질 > 양**
   - 7B 고품질 토큰이 수조 개 저품질 토큰보다 나을 수 있음
   - 품질, 양, 다양성이 모두 중요

### 다국어 모델의 현실
1. **심각한 언어 불균형**
   - 영어: 45.88% vs 버마어: 0.0077%
   - 불균형 비율 최대 231배

2. **실질적 영향**
   - 성능 차이: 영어 86% vs 텔루구어 30% (MMLU)
   - 비용 차이: 버마어가 영어보다 10배
   - 안전성 차이: 중국어로 허위 정보 더 쉽게 생성

3. **해결책**
   - 언어별 특화 모델 개발
   - 토크나이저 최적화
   - 고품질 다국어 데이터 큐레이션

### 도메인 특화의 필요성
1. **범용 모델의 한계**
   - 인터넷 데이터에 없는 전문 지식 부족
   - 의료, 생명과학 등 민감한 데이터 접근 불가

2. **성공 사례**
   - AlphaFold: 단백질 구조 예측 혁명
   - Med-PaLM2: 의료 질문 답변
   - BioNeMo: 신약 개발 가속화

3. **투자 가치**
   - 높은 정확도가 중요한 분야
   - 전문 데이터 확보 가능 시
   - 특정 도메인에 집중할 때

---

## 토론 질문

### 데이터 품질
1. Common Crawl의 품질 문제를 어떻게 해결할 수 있을까?
2. 고품질 데이터를 판별하는 기준은 무엇이어야 할까?
3. 합성 데이터(AI가 생성한 데이터)를 학습에 사용하는 것의 장단점은?

### 다국어 지원
1. 저자원 언어를 위한 현실적인 해결책은 무엇일까?
2. 모든 언어를 지원하는 단일 모델 vs 언어별 특화 모델, 어느 것이 나을까?
3. 토큰화 비효율성을 근본적으로 해결할 방법은?

### 도메인 특화
1. 우리 팀/회사가 도메인 특화 모델을 만들어야 할까?
2. 범용 모델을 파인튜닝 vs 처음부터 학습, 언제 어느 것을 선택해야 할까?
3. 의료/법률 같은 고위험 분야에서 AI를 어디까지 신뢰할 수 있을까?

### 윤리적 고려사항
1. 편향된 데이터로 학습된 모델의 책임은 누구에게 있을까?
2. 인터넷 데이터를 무단으로 크롤링하여 학습하는 것은 정당한가?
3. 언어 불균형을 방치하는 것은 디지털 격차를 심화시키는가?

---

## 실습 아이디어

### 초급
1. **토크나이저 실험**
   - 같은 문장을 여러 언어로 번역
   - 각 언어별 토큰 수 비교
   - OpenAI Tokenizer 도구 사용

2. **모델 성능 비교**
   - 같은 질문을 영어와 모국어로 GPT에게 질문
   - 답변 품질과 속도 비교

### 중급
1. **도메인별 벤치마크**
   - 특정 도메인(예: 법률, 의료) 질문 세트 준비
   - 범용 모델 vs 특화 모델 성능 비교
   - 정확도, 할루시네이션 빈도 측정

2. **데이터 필터링 실험**
   - 저품질 웹 데이터 수집
   - 다양한 필터링 휴리스틱 적용
   - 필터링 전후 모델 성능 비교

### 고급
1. **다국어 모델 파인튜닝**
   - 저자원 언어 데이터 수집
   - 기존 모델 파인튜닝
   - 성능 향상 측정

2. **도메인 특화 모델 구축**
   - 특정 도메인 데이터 큐레이션
   - 처음부터 학습 vs 파인튜닝 비교
   - ROI 분석

---

**다음**: [2.2 Modeling (모델링) →](./2.2-modeling.md)

[← 목차로 돌아가기](./README.md)
