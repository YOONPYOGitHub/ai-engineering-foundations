# 3.4 AI as a Judge (AI 평가자)

> "LangChain 2023 보고서: 플랫폼 평가의 58%가 AI Judge로 수행됨"

[← 목차로 돌아가기](./README.md)

---

## 📋 목차
- [핵심 개념](#핵심-개념)
- [3.4.1 Why AI as a Judge?](#341-why-ai-as-a-judge)
- [3.4.2 How to Use AI as a Judge](#342-how-to-use-ai-as-a-judge)
- [3.4.3 Limitations of AI as a Judge](#343-limitations-of-ai-as-a-judge)
- [3.4.4 What Models Can Act as Judges?](#344-what-models-can-act-as-judges)
- [핵심 요약](#핵심-요약)
- [토론 질문](#토론-질문)

---

## 핵심 개념

### AI as a Judge란?

**정의**: AI를 사용하여 AI 응답을 평가하는 접근법

- **AI Judge**: 다른 AI 모델을 평가하는 데 사용되는 AI 모델
- **동의어**: LLM as a Judge

**역사**:
- 아이디어는 오래전부터 존재
- 2020년 GPT-3 출시 이후 실용화
- 현재 가장 흔한 AI 평가 방법 중 하나

### Exact vs Subjective Evaluation

| 유형 | 특징 | 예시 |
|------|------|------|
| Exact | 모호함 없음 | Functional Correctness |
| **Subjective** | 판단자에 따라 달라짐 | **AI as a Judge** |

> ⚠️ AI as a Judge는 **주관적**: 모델과 프롬프트에 따라 결과가 달라짐

---

## 3.4.1 Why AI as a Judge?

### 장점

| 장점 | 설명 |
|------|------|
| **빠름** | 인간보다 훨씬 빠른 평가 |
| **저렴함** | 인간 평가자보다 비용 효율적 |
| **사용 편의성** | 쉽게 설정 가능 |
| **참조 데이터 불필요** | 프로덕션 환경에서 유용 |
| **유연성** | 어떤 기준으로든 평가 가능 |

### 인간과의 일치도

**연구 결과 (Zheng et al., 2023)**:

```
MT-Bench에서:
- GPT-4와 인간 일치율: 85%
- 인간 간 일치율: 81%

→ GPT-4가 인간 간 일치율보다 높음!
```

**AlpacaEval (Dubois et al., 2023)**:
- AI Judge와 LMSYS Chatbot Arena 상관관계: **0.98**

### 설명 가능성

AI Judge는 점수뿐만 아니라 **판단 이유**도 제공

```
질문: "파이썬에서 리스트를 뒤집는 방법은?"
응답: "list.reverse()를 사용하세요."

AI Judge 평가:
점수: 4/5
이유: "올바른 방법을 제시했지만, 원본 리스트를 변경한다는 
      점과 reversed()라는 대안을 언급하지 않아 1점 감점"
```

---

## 3.4.2 How to Use AI as a Judge

### 세 가지 평가 접근법

#### 1. 단독 품질 평가

```
프롬프트:
"다음 질문과 답변이 주어졌을 때, 답변이 질문에 얼마나 
좋은지 1-5점으로 평가하세요.
- 1: 매우 나쁨
- 5: 매우 좋음

질문: [QUESTION]
답변: [ANSWER]
점수:"
```

#### 2. 참조 데이터와 비교

```
프롬프트:
"다음 질문, 참조 답변, 생성된 답변이 주어졌을 때,
생성된 답변이 참조 답변과 같은지 평가하세요.
True 또는 False를 출력하세요.

질문: [QUESTION]
참조 답변: [REFERENCE ANSWER]
생성된 답변: [GENERATED ANSWER]"
```

#### 3. 두 응답 비교 (선호도 예측)

```
프롬프트:
"다음 질문과 두 답변이 주어졌을 때, 어떤 답변이 
더 좋은지 평가하세요. A 또는 B를 출력하세요.

질문: [QUESTION]
A: [FIRST ANSWER]
B: [SECOND ANSWER]
더 좋은 답변은:"
```

### 평가 기준 (Criteria)

**일반적인 내장 기준들**:

| 도구 | 내장 기준 |
|------|----------|
| **Azure AI Studio** | Groundedness, Relevance, Coherence, Fluency, Similarity |
| **MLflow** | Faithfulness, Relevance |
| **LangChain** | Conciseness, Relevance, Correctness, Coherence, Harmfulness, Helpfulness, ... |
| **Ragas** | Faithfulness, Answer Relevance |

**커스텀 기준 예시**:
- 롤플레잉 챗봇: "이 응답이 간달프가 할 법한 말인가?"
- 상품 사진 생성: "이 이미지에서 상품의 신뢰성을 1-5로 평가하세요"

### 효과적인 프롬프트 구성

1. **태스크 설명**
   - 모델이 수행할 작업 명확히 설명
   - 예: "질문과 답변 사이의 관련성을 평가하세요"

2. **평가 기준**
   - 상세할수록 좋음
   - 예: "주요 초점은 생성된 답변이 질문에 대해 충분한 정보를 포함하는지..."

3. **점수 체계**
   - **분류**: good/bad, relevant/irrelevant/neutral
   - **이산 수치**: 1-5 (권장)
   - **연속 수치**: 0-1

> 💡 언어 모델은 숫자보다 텍스트를 더 잘 다룸
> - 분류 > 이산 수치 > 연속 수치
> - 점수 범위가 넓을수록 성능 저하

### 예시 포함의 중요성

**Azure AI Studio의 Relevance 프롬프트 (일부)**:

```
귀하의 과제는 생성된 답변과 질문 사이의 관련성을 
정답을 기반으로 1-5 사이로 점수 매기고, 
점수의 이유도 제공하는 것입니다.

주요 초점은 생성된 답변이 정답에 따라 주어진 질문을 
다루기에 충분한 정보를 포함하는지 여부입니다...

생성된 답변이 정답과 모순되면 1-2의 낮은 점수를 받습니다.

예시: "하늘이 파란가요?"라는 질문에 정답은 
"예, 하늘은 파랗습니다."이고 생성된 답변이 
"아니오, 하늘은 파랗지 않습니다."인 경우

이 예에서 생성된 답변은 정답과 모순됩니다...
이 불일치로 1-2의 낮은 점수가 됩니다.
```

### AI Judge = 모델 + 프롬프트

> ⚠️ 모델, 프롬프트, 샘플링 파라미터 중 하나라도 바뀌면 **다른 Judge**

---

## 3.4.3 Limitations of AI as a Judge

### 1. 비일관성 (Inconsistency)

**문제**:
- 같은 입력에 다른 점수
- 프롬프트가 약간 달라도 다른 점수
- 두 번 실행해도 다른 점수

**완화 방법**:
- 샘플링 변수 고정 (Chapter 2)
- 프롬프트에 예시 추가

**Zheng et al. 연구**:
```
예시 없는 GPT-4 일관성: 65%
예시 포함 GPT-4 일관성: 77.5%

⚠️ 하지만 높은 일관성 ≠ 높은 정확도
    (일관되게 틀릴 수 있음)
```

### 2. 기준 모호성 (Criteria Ambiguity)

**문제**: AI Judge 기준이 **표준화되지 않음**

**예시: Faithfulness 기준 비교**

| 도구 | 점수 체계 |
|------|----------|
| MLflow | 1-5 |
| Ragas | 0, 1 |
| LlamaIndex | YES/NO |

→ 같은 이름의 기준이지만 점수가 완전히 다름!

**시간에 따른 변화**:
- 지난달: 일관성 점수 90%
- 이번달: 일관성 점수 92%

→ 애플리케이션이 개선되었나? 아니면 Judge가 바뀌었나?

> ⚠️ 모델과 프롬프트를 볼 수 없는 AI Judge는 신뢰하지 마세요

### 3. 비용과 지연 시간 증가

**비용**:
```
GPT-4로 생성 + GPT-4로 평가 = API 비용 2배

3가지 기준 평가 (품질, 사실성, 독성) 
= API 호출 4배
```

**완화 방법**:
- 약한 모델을 Judge로 사용
- **Spot-checking**: 일부 응답만 평가

**지연 시간**:
- 응답 반환 전에 평가하면 → 지연 시간 증가
- 엄격한 지연 요구사항이 있는 앱에서는 문제

### 4. AI Judge의 편향 (Biases)

#### Self-bias (자기 편향)
- 모델이 **자신의 응답**을 선호

```
Zheng et al. 실험:
- GPT-4 자기 편향: +10% win rate
- Claude-v1 자기 편향: +25% win rate
```

#### Position Bias (위치 편향)
- 첫 번째 옵션을 선호 (AI)
- 마지막 옵션을 선호 (인간 - Recency Bias)

**완화 방법**:
- 순서를 바꿔서 여러 번 테스트
- 신중하게 설계된 프롬프트

#### Verbosity Bias (장문 편향)
- 품질과 무관하게 **긴 응답**을 선호

```
Wu and Aji (2023):
GPT-4와 Claude-1 모두 
- 오류가 있는 100단어 응답 > 정확한 50단어 응답

Saito et al. (2023):
길이 차이가 2배 이상이면 → 거의 항상 긴 응답 선호
```

> 💡 GPT-4는 GPT-3.5보다 이 편향이 적음
> → 모델이 강해지면 편향이 줄어들 수 있음

---

## 3.4.4 What Models Can Act as Judges?

### 세 가지 시나리오

| 시나리오 | 설명 | 장단점 |
|---------|------|--------|
| **강한 모델** | 더 강한 모델이 평가 | 더 좋은 판단, 비용 높음 |
| **동일 모델** | 자기 자신을 평가 | Self-critique, 자기 편향 위험 |
| **약한 모델** | 더 약한 모델이 평가 | 비용 낮음, 판단 품질 낮을 수 있음 |

### 강한 모델 사용

**사용 사례**:
- 저렴한 내부 모델로 응답 생성
- GPT-4로 1% 응답 평가

**장점**:
- 더 좋은 판단
- 약한 모델 개선 가이드 가능

**문제**:
- 가장 강한 모델은 누가 평가?
- 대안 평가 방법 필요

### 자기 평가 (Self-Evaluation)

**Self-critique / Self-ask**:

```
프롬프트 [사용자]: 10+3은?
첫 응답 [AI]: 30
자기 비평 [AI]: 이 답이 맞나?
최종 응답 [AI]: 아니, 틀렸습니다. 정답은 13입니다.
```

**용도**:
- Sanity check
- 응답 개선 유도

### 약한 모델 사용

**논쟁**:
- "판단은 생성보다 쉽다"
- 누구나 노래가 좋은지 판단할 수 있지만, 모두가 작곡할 수 있는 것은 아님

**현실**:
- Zheng et al.: 강한 모델이 인간 선호와 더 상관관계 높음
- 대부분 가능한 강한 모델 사용

---

### 특화된 Judge 모델

#### Reward Model
- 입력: (prompt, response)
- 출력: 응답 품질 점수 (0-1)
- 예: **Cappy** (Google, 360M 파라미터)

#### Reference-based Judge
- 입력: (생성 응답, 참조 응답)
- 출력: 유사도 또는 품질 점수
- 예: **BLEURT**, **Prometheus**

#### Preference Model
- 입력: (prompt, response 1, response 2)
- 출력: 어떤 응답이 더 좋은지
- 예: **PandaLM**, **JudgeLM**

**PandaLM 예시**:
```
입력:
- Human Prompt: "..."
- Response 1: "..."
- Response 2: "..."

출력:
- Winner: Response 1
- 근거: "Response 1은 더 구체적인 예시를 
        제공하고 논리적 구조가 명확합니다..."
```

> 💡 작고 특화된 Judge가 크고 범용적인 Judge보다 
> 특정 판단에서 더 신뢰할 수 있을 수 있음

---

## 핵심 요약

### AI as a Judge 요약

| 측면 | 내용 |
|------|------|
| **정의** | AI로 AI 응답 평가 |
| **장점** | 빠름, 저렴, 유연, 설명 가능 |
| **한계** | 비일관성, 모호함, 비용, 편향 |
| **편향** | Self-bias, Position bias, Verbosity bias |
| **Judge 유형** | 범용 vs 특화 (Reward, Reference, Preference) |

### 사용 권장 사항

1. **모델과 프롬프트를 공개하는 Judge만 신뢰**
2. **Exact evaluation이나 Human evaluation으로 보완**
3. **편향을 인식하고 완화 전략 적용**
4. **시간에 따른 Judge 변화 모니터링**
5. **비용-품질 트레이드오프 고려**

---

## 토론 질문

### 이해도 확인
1. AI as a Judge가 "주관적"인 이유는 무엇인가?
2. Self-bias와 Verbosity bias를 각각 어떻게 완화할 수 있는가?

### 실용적 적용
1. 우리 프로젝트에서 AI Judge를 어떻게 활용할 수 있을까?
2. 비용과 품질 사이에서 어떤 트레이드오프를 선택할 것인가?

### 심화 토론
1. AI로 AI를 평가하는 것이 순환 논리인가?
2. 미래에 AI Judge가 인간 평가자를 완전히 대체할 수 있을까?

---

**다음**: [3.5 비교 평가로 모델 순위 매기기 →](./3.5-comparative-evaluation.md)

[← 이전: 3.3 정확한 평가](./3.3-exact-evaluation.md) | [목차로 돌아가기](./README.md)
